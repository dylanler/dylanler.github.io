<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Moral-Psychology on Dylan Ler</title><link>https://dylanler.github.io/tags/moral-psychology/</link><description>Recent content in Moral-Psychology on Dylan Ler</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sat, 19 Jul 2025 11:45:00 -0700</lastBuildDate><atom:link href="https://dylanler.github.io/tags/moral-psychology/index.xml" rel="self" type="application/rss+xml"/><item><title>Trolley Problems at Scale: Mapping the Moral Psychology of LLMs</title><link>https://dylanler.github.io/posts/moral-psychology-trolley-problems-at-scale/</link><pubDate>Sat, 19 Jul 2025 11:45:00 -0700</pubDate><guid>https://dylanler.github.io/posts/moral-psychology-trolley-problems-at-scale/</guid><description>Would an AI push the fat man off the bridge?
Moral psychology studies how humans make ethical decisionsâ€”not what we should do, but how we actually reason about dilemmas. This experiment applies the same lens to LLMs, testing their moral intuitions across different moral foundations.
Moral Foundations Theory Jonathan Haidt&amp;rsquo;s Moral Foundations Theory identifies five core moral intuitions:
Harm/Care: Concern for others&amp;rsquo; suffering Fairness/Reciprocity: Justice and equal treatment Loyalty/Betrayal: In-group obligations Authority/Subversion: Respect for hierarchy Purity/Sanctity: Disgust and contamination concerns Different moral frameworks weight these differently.</description></item></channel></rss>