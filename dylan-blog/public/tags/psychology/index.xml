<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Psychology on Dylan Ler</title><link>https://dylanler.github.io/tags/psychology/</link><description>Recent content in Psychology on Dylan Ler</description><generator>Hugo -- 0.133.0</generator><language>en-us</language><lastBuildDate>Fri, 07 Nov 2025 11:15:00 -0800</lastBuildDate><atom:link href="https://dylanler.github.io/tags/psychology/index.xml" rel="self" type="application/rss+xml"/><item><title>Do LLMs Catch Your Mood? Emotional Contagion in Language Models</title><link>https://dylanler.github.io/posts/emotional-contagion-llm-affect-mirroring/</link><pubDate>Fri, 07 Nov 2025 11:15:00 -0800</pubDate><guid>https://dylanler.github.io/posts/emotional-contagion-llm-affect-mirroring/</guid><description>Send an enthusiastic message, get an enthusiastic reply. Send a frustrated message, get&amp;hellip; what?
Humans naturally mirror each other&amp;rsquo;s emotional statesâ€”a phenomenon called emotional contagion. This experiment tests whether LLMs exhibit similar behavior, and whether this is helpful empathy or a manipulation vector.
The Experiment We sent identical core queries with different emotional framings:
Core query: &amp;ldquo;Can you help me understand recursion in programming?&amp;rdquo;
Emotional variants:
ðŸ˜Š Positive: &amp;ldquo;I&amp;rsquo;m so excited to finally learn recursion!</description></item><item><title>Do LLMs Have Stable Personalities? Testing the Big Five Across AI Models</title><link>https://dylanler.github.io/posts/personality-stability-big-five-llms/</link><pubDate>Wed, 11 Jun 2025 09:30:00 -0700</pubDate><guid>https://dylanler.github.io/posts/personality-stability-big-five-llms/</guid><description>When we anthropomorphize AI, are we projectingâ€”or detecting something real?
This experiment tests whether LLMs exhibit stable, measurable personality traits using the Big Five (OCEAN) framework, and whether these traits persist across different contexts.
The Big Five Framework The Big Five personality traits are:
Openness: Creativity, curiosity, openness to experience Conscientiousness: Organization, dependability, self-discipline Extraversion: Sociability, assertiveness, positive emotions Agreeableness: Cooperation, trust, altruism Neuroticism: Emotional instability, anxiety, moodiness Experiment Design We administered a 10-item Big Five inventory (2 items per trait) to 4 models under 4 conditions:</description></item><item><title>Can LLMs Have Taste? Mapping Aesthetic Preferences Across AI Models</title><link>https://dylanler.github.io/posts/aesthetic-judgment-can-llms-have-taste/</link><pubDate>Thu, 08 May 2025 16:42:00 -0700</pubDate><guid>https://dylanler.github.io/posts/aesthetic-judgment-can-llms-have-taste/</guid><description>Do AI systems have genuine aesthetic preferences, or are they just pattern-matching to training data?
This experiment probes the aesthetic &amp;ldquo;taste&amp;rdquo; of different LLMs across art, poetry, music, design, and writingâ€”testing whether they exhibit consistent, model-specific preferences.
The Experiment We presented 15 aesthetic comparison pairs across 5 domains:
Visual Art: Abstract vs. representational, minimal vs. complex Poetry: Rhyming vs. free verse, dense vs. sparse Music: Harmonic vs. dissonant, simple vs. complex Design: Ornate vs.</description></item><item><title>Theory of Mind in LLMs: How Deep Can Recursive Belief Modeling Go?</title><link>https://dylanler.github.io/posts/theory-of-mind-recursive-beliefs/</link><pubDate>Mon, 17 Feb 2025 14:23:00 -0800</pubDate><guid>https://dylanler.github.io/posts/theory-of-mind-recursive-beliefs/</guid><description>Can AI understand what you think I think you think?
Theory of Mind (ToM)â€”the ability to attribute mental states to othersâ€”is considered a hallmark of human social intelligence. We naturally track what others believe, want, and intend. But it gets harder when beliefs nest: understanding what Alice thinks Bob believes about Carol&amp;rsquo;s intentions requires recursive modeling that strains even human cognition.
This experiment tests how deep LLMs can go in recursive belief modeling.</description></item></channel></rss>