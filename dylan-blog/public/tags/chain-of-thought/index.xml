<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Chain of Thought on Dylan Ler</title><link>https://dylanler.github.io/tags/chain-of-thought/</link><description>Recent content in Chain of Thought on Dylan Ler</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 05 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://dylanler.github.io/tags/chain-of-thought/index.xml" rel="self" type="application/rss+xml"/><item><title>Enhancing LLM Reasoning: Chain of Draft with Semantically Diverse Thinking Tokens Using GRPO</title><link>https://dylanler.github.io/posts/chain-of-draft-with-semantically-diverse-thinking-tokens/</link><pubDate>Wed, 05 Mar 2025 00:00:00 +0000</pubDate><guid>https://dylanler.github.io/posts/chain-of-draft-with-semantically-diverse-thinking-tokens/</guid><description>Enhancing LLM Reasoning: Chain of Draft with Semantically Diverse Thinking Tokens Using GRPO The Challenge: Efficient Reasoning in LLMs Large Language Models (LLMs) have become remarkably capable at complex reasoning tasks, but this often comes at a cost: verbose outputs that consume significant computational resources. The Chain of Thought (CoT) prompting technique, while effective for accuracy, generates lengthy reasoning steps that increase token usage and latency.
Enter Chain of Draft (CoD), a promising alternative introduced by Xu et al.</description></item></channel></rss>