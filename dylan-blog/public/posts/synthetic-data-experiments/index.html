<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Synthetic Data Experiments with LLMs | Dylan Ler</title>
<meta name=keywords content="AI,Synthetic Data,LLMs,Data Generation,Machine Learning"><meta name=description content="A comprehensive guide exploring four innovative methods for generating high-quality synthetic data for Large Language Models, including persona-driven web crawling, graph-based reasoning, research paper extraction, and curriculum learning."><meta name=author content><link rel=canonical href=https://dylanler.github.io/posts/synthetic-data-experiments/><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://dylanler.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dylanler.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dylanler.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://dylanler.github.io/apple-touch-icon.png><link rel=mask-icon href=https://dylanler.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://dylanler.github.io/posts/synthetic-data-experiments/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="Synthetic Data Experiments with LLMs"><meta property="og:description" content="A comprehensive guide exploring four innovative methods for generating high-quality synthetic data for Large Language Models, including persona-driven web crawling, graph-based reasoning, research paper extraction, and curriculum learning."><meta property="og:type" content="article"><meta property="og:url" content="https://dylanler.github.io/posts/synthetic-data-experiments/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-01-19T20:45:48-08:00"><meta property="article:modified_time" content="2025-01-19T20:45:48-08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Synthetic Data Experiments with LLMs"><meta name=twitter:description content="A comprehensive guide exploring four innovative methods for generating high-quality synthetic data for Large Language Models, including persona-driven web crawling, graph-based reasoning, research paper extraction, and curriculum learning."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dylanler.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Synthetic Data Experiments with LLMs","item":"https://dylanler.github.io/posts/synthetic-data-experiments/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Synthetic Data Experiments with LLMs","name":"Synthetic Data Experiments with LLMs","description":"A comprehensive guide exploring four innovative methods for generating high-quality synthetic data for Large Language Models, including persona-driven web crawling, graph-based reasoning, research paper extraction, and curriculum learning.","keywords":["AI","Synthetic Data","LLMs","Data Generation","Machine Learning"],"articleBody":"Generating High-Quality Synthetic Data for Large Language Models Introduction In the dynamic landscape of artificial intelligence (AI), Large Language Models (LLMs) stand out for their remarkable ability to understand and generate human-like text. Their performance, however, is largely influenced by the quality and diversity of their training data. This guide explores four innovative methods for generating high-quality synthetic data—each designed to broaden LLMs’ capabilities and help them excel across a wide range of tasks. Additionally, we’ll demonstrate how to combine multiple LLMs with varying parameters to further enhance data diversity.\nOverview of Synthetic Data Generation The quest for diverse and context-rich training data has led to creative new approaches in synthetic data generation. Below, we outline four methods that target different aspects of LLM training:\nPersona-Driven Web Crawling Agents Graph of Thought + GraphRAG Research Paper Extraction with Vision-Language Models Curriculum Learning Inspired by Child Development We’ll also discuss a unified strategy to integrate these approaches into a single workflow and show how to leverage multiple LLMs—each configured with distinct parameters—to maximize diversity.\nMethod 1: Persona-Driven Web Crawling Agents Concept\nDeploying a large number of virtual personas—each with unique backgrounds, beliefs, and goals—to crawl and generate text from web content. The personas can use their individual “points of view” to produce highly varied and contextually rich data.\nKey Highlights\nPersona Hub: Store a large collection of persona templates (up to a billion or more). Web Crawling Agents: Agents use these personas to navigate the web, collecting or summarizing relevant information. Multi-turn Prompt Cycles: Each persona interacts with content in multiple rounds, ensuring a deeper and more diverse dataset. Method 2: Graph of Thought + GraphRAG Concept\nMarry graph-based reasoning with retrieval-augmented generation to create synthetic data grounded in structured knowledge. Using a knowledge graph and graph neural networks, this approach supports multi-hop reasoning, ensuring more nuanced and factually accurate data.\nKey Highlights\nKnowledge Graph Construction: Captures entities, relationships, and domain knowledge. Graph Neural Networks: Facilitate advanced reasoning across multiple knowledge nodes. Graph-based Retrieval + RAG Generation: Integrates structured information into the generation process for coherence and precision. Method 3: Research Paper Extraction with Vision-Language Models Concept\nHigh-quality synthetic data can be seeded with scientific rigor by analyzing research papers. Vision-language models parse PDF layouts, figures, and tables to extract meaningful insights, which are then transformed into novel training data.\nKey Highlights\nVision-Language Models: Capable of parsing complex document structures. PDF Parsing and Content Extraction: Retrieves text, figures, and tables for deeper analysis. Information Synthesis: Merges extracted content with knowledge graphs to produce new, academically grounded data points. Method 4: Curriculum Learning Inspired by Child Development Concept\nThis method adopts a curriculum learning framework that emulates child cognitive development. The LLM is systematically introduced to tasks of increasing complexity—starting from basic perception and advancing through language acquisition and abstract reasoning.\nKey Highlights\nDevelopmental Stages: Each stage targets a specific cognitive milestone. Stage-Specific Data Generation: Tasks grow more challenging, reflecting real-world learning progressions. Structured Curriculum + Evaluation: A progressive roadmap ensures the model is exposed to increasingly complex data. Integrating Multiple LLMs with Different Parameters To maximize diversity and quality, it’s crucial to use a range of LLMs, each with different parameter settings (e.g., temperature, top_p, max_length, model size, or even entirely different architectures). Varying these parameters introduces controlled randomness and multiple “voices,” leading to a richer, more generalized training dataset.\nExample: Python Code for Generating Diverse Synthetic Data Below is a simplified example script that demonstrates how to generate synthetic data by prompting multiple LLMs (Hugging Face Transformers, OpenAI’s API, or any other frameworks you prefer). It includes:\nPersona-driven prompts Different parameter settings for each model Basic placeholders for hooking in advanced modules (e.g., knowledge graphs, vision-language extraction) Note: This is illustrative and may need adaptation or additional libraries for web crawling, graph-based reasoning, or PDF parsing.\nimport random import time from typing import List # Example: Hugging Face Transformers from transformers import pipeline, set_seed ######################### # 1. Configuration # ######################### # Define a set of different models (using latest LLMs) model_configs = [ { \"model_name\": \"gpt-4o\", # GPT-4o \"temperature\": 0.7, \"top_p\": 0.9, \"max_tokens\": 4096 }, { \"model_name\": \"gemini-1.5-pro\", # Google's Gemini Pro \"temperature\": 0.9, \"top_p\": 0.8, \"max_tokens\": 2048 }, { \"model_name\": \"claude-3-sonnet-20240229\", # Claude 3 Sonnet \"temperature\": 0.8, \"top_p\": 0.85, \"max_tokens\": 4096 } ] # Example persona templates personas = [ { \"name\": \"Science-Enthusiast-Bot\", \"background\": \"Interested in physics, mathematics, and all things scientific.\", \"tone\": \"curious, analytical\" }, { \"name\": \"LiteraryCritic-Bot\", \"background\": \"Avid reader, loves poetry and literature analysis.\", \"tone\": \"insightful, reflective\" }, # Add more personas ] # Sample knowledge graph or context snippet (placeholder) knowledge_graph_snippet = \"Entity A is related to Entity B via Relationship X.\" # Simulated method for retrieving information from a web crawling agent (placeholder) def persona_based_web_crawl(persona_prompt: str) -\u003e str: \"\"\" In a real-world scenario, this would: 1. Initiate a crawler with the persona's perspective. 2. Gather data from relevant websites. 3. Summarize or transform the content. For now, we return a static snippet to simulate. \"\"\" # Simulated snippet of retrieved web content return f\"Recently discovered content relevant to {persona_prompt}.\" ############################## # 2. Synthetic Data Function # ############################## def generate_synthetic_samples(num_samples: int = 5) -\u003e List[str]: \"\"\" Generate synthetic data samples using multiple state-of-the-art LLMs. \"\"\" synthetic_data = [] for _ in range(num_samples): # Randomly pick a model config cfg = random.choice(model_configs) model_name = cfg[\"model_name\"] temperature = cfg[\"temperature\"] top_p = cfg[\"top_p\"] max_tokens = cfg[\"max_tokens\"] # Select appropriate client based on model if \"gpt-4\" in model_name: response = openai.ChatCompletion.create( model=model_name, messages=[{\"role\": \"user\", \"content\": final_prompt}], temperature=temperature, top_p=top_p, max_tokens=max_tokens ) output = response.choices[0].message.content elif \"gemini\" in model_name: response = genai.generate_text( model=model_name, prompt=final_prompt, temperature=temperature, top_p=top_p, max_output_tokens=max_tokens ) output = response.text elif \"claude\" in model_name: response = anthropic.messages.create( model=model_name, max_tokens=max_tokens, temperature=temperature, top_p=top_p, messages=[{\"role\": \"user\", \"content\": final_prompt}] ) output = response.content[0].text # Add synthetic sample to our collection synthetic_data.append(output) # Sleep briefly to avoid rate limits time.sleep(2) return synthetic_data ##################### # 3. Main Execution # ##################### if __name__ == \"__main__\": import torch import openai import google.generativeai as genai import anthropic # Generate synthetic data num_samples_to_generate = 5 samples = generate_synthetic_samples(num_samples=num_samples_to_generate) # Display results for i, sample in enumerate(samples, start=1): print(f\"\\n=== Synthetic Sample {i} ===\") print(sample) What This Code Demonstrates Multiple LLMs: We define several model configurations—each with its own model name, temperature, top_p, and max_tokens. Persona Variation: Sample personas inject varied styles, knowledge, and viewpoints. Diverse Prompting: We combine persona backgrounds, knowledge graph snippets, and web-crawled content (simulated) into a final prompt, enhancing contextual richness. Parameter Randomization: Each sample uses a random persona and a random model config, increasing diversity. Extending the Code Graph of Thought + GraphRAG: Integrate a knowledge graph and retrieval-augmented generation flow. You might replace or expand the knowledge_graph_snippet with real queries to a knowledge base. Vision-Language for Research Papers: Parse PDFs (using libraries like pdfplumber, PyMuPDF, or specialized vision-language models) to extract figures, tables, and text. Incorporate these extracts into prompts. Curriculum Learning: Structure prompts into “stages,” gradually increasing complexity. Early prompts might focus on simple Q\u0026A, while advanced prompts might involve multi-turn dialogue with references to multiple knowledge sources. Practical Applications Each method outlined—persona-driven crawling, graph-based reasoning, research paper parsing, and curriculum design—contributes a unique dimension to synthetic data creation:\nEnhanced Diversity: Persona-based text and multi-model generation yield a variety of styles and vocabularies. Deeper Reasoning: Graph-based approaches ensure factual coherence and complex multi-hop reasoning. Scientific Rigor: Research paper extraction injects credible, domain-specific insights into training data. Progressive Learning: Curriculum-based tasks mirror how humans acquire new skills over time. Final Thoughts By combining multiple data generation strategies and leveraging various LLMs with distinct parameter settings, you can create synthetic datasets that are both highly diverse and rich in context. This, in turn, enhances the robustness and generalization capabilities of trained LLMs—paving the way for next-level AI performance.\n","wordCount":"1291","inLanguage":"en","datePublished":"2025-01-19T20:45:48-08:00","dateModified":"2025-01-19T20:45:48-08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://dylanler.github.io/posts/synthetic-data-experiments/"},"publisher":{"@type":"Organization","name":"Dylan Ler","logo":{"@type":"ImageObject","url":"https://dylanler.github.io/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dylanler.github.io/ accesskey=h title="Dylan Ler (Alt + H)">Dylan Ler</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://dylanler.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://dylanler.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://dylanler.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://dylanler.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://dylanler.github.io/faq/ title=FAQ><span>FAQ</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dylanler.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://dylanler.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Synthetic Data Experiments with LLMs</h1><div class=post-description>A comprehensive guide exploring four innovative methods for generating high-quality synthetic data for Large Language Models, including persona-driven web crawling, graph-based reasoning, research paper extraction, and curriculum learning.</div><div class=post-meta><span title='2025-01-19 20:45:48 -0800 PST'>January 19, 2025</span>&nbsp;·&nbsp;7 min</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#generating-high-quality-synthetic-data-for-large-language-models aria-label="Generating High-Quality Synthetic Data for Large Language Models">Generating High-Quality Synthetic Data for Large Language Models</a><ul><li><a href=#introduction aria-label=Introduction>Introduction</a></li><li><a href=#overview-of-synthetic-data-generation aria-label="Overview of Synthetic Data Generation">Overview of Synthetic Data Generation</a></li></ul></li><li><a href=#method-1-persona-driven-web-crawling-agents aria-label="Method 1: Persona-Driven Web Crawling Agents">Method 1: Persona-Driven Web Crawling Agents</a></li><li><a href=#method-2-graph-of-thought--graphrag aria-label="Method 2: Graph of Thought + GraphRAG">Method 2: Graph of Thought + GraphRAG</a></li><li><a href=#method-3-research-paper-extraction-with-vision-language-models aria-label="Method 3: Research Paper Extraction with Vision-Language Models">Method 3: Research Paper Extraction with Vision-Language Models</a></li><li><a href=#method-4-curriculum-learning-inspired-by-child-development aria-label="Method 4: Curriculum Learning Inspired by Child Development">Method 4: Curriculum Learning Inspired by Child Development</a></li><li><a href=#integrating-multiple-llms-with-different-parameters aria-label="Integrating Multiple LLMs with Different Parameters">Integrating Multiple LLMs with Different Parameters</a></li><li><a href=#example-python-code-for-generating-diverse-synthetic-data aria-label="Example: Python Code for Generating Diverse Synthetic Data">Example: Python Code for Generating Diverse Synthetic Data</a><ul><li><a href=#what-this-code-demonstrates aria-label="What This Code Demonstrates">What This Code Demonstrates</a></li><li><a href=#extending-the-code aria-label="Extending the Code">Extending the Code</a></li></ul></li><li><a href=#practical-applications aria-label="Practical Applications">Practical Applications</a><ul><li><a href=#final-thoughts aria-label="Final Thoughts">Final Thoughts</a></li></ul></li></ul></div></details></div><div class=post-content><h2 id=generating-high-quality-synthetic-data-for-large-language-models>Generating High-Quality Synthetic Data for Large Language Models<a hidden class=anchor aria-hidden=true href=#generating-high-quality-synthetic-data-for-large-language-models>#</a></h2><h3 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h3><p>In the dynamic landscape of artificial intelligence (AI), <strong>Large Language Models (LLMs)</strong> stand out for their remarkable ability to understand and generate human-like text. Their performance, however, is largely influenced by the <strong>quality</strong> and <strong>diversity</strong> of their training data. This guide explores four innovative methods for generating high-quality synthetic data—each designed to broaden LLMs&rsquo; capabilities and help them excel across a wide range of tasks. Additionally, we&rsquo;ll demonstrate how to combine <strong>multiple LLMs with varying parameters</strong> to further enhance data diversity.</p><h3 id=overview-of-synthetic-data-generation>Overview of Synthetic Data Generation<a hidden class=anchor aria-hidden=true href=#overview-of-synthetic-data-generation>#</a></h3><p>The quest for diverse and context-rich training data has led to creative new approaches in <strong>synthetic data generation</strong>. Below, we outline four methods that target different aspects of LLM training:</p><ol><li><strong>Persona-Driven Web Crawling Agents</strong></li><li><strong>Graph of Thought + GraphRAG</strong></li><li><strong>Research Paper Extraction with Vision-Language Models</strong></li><li><strong>Curriculum Learning Inspired by Child Development</strong></li></ol><p>We&rsquo;ll also discuss a unified strategy to integrate these approaches into a single workflow and show how to leverage multiple LLMs—each configured with distinct parameters—to maximize diversity.</p><hr><h2 id=method-1-persona-driven-web-crawling-agents>Method 1: Persona-Driven Web Crawling Agents<a hidden class=anchor aria-hidden=true href=#method-1-persona-driven-web-crawling-agents>#</a></h2><p><strong>Concept</strong><br>Deploying a <strong>large number of virtual personas</strong>—each with unique backgrounds, beliefs, and goals—to crawl and generate text from web content. The personas can use their individual &ldquo;points of view&rdquo; to produce highly varied and contextually rich data.</p><p><strong>Key Highlights</strong></p><ul><li><strong>Persona Hub</strong>: Store a large collection of persona templates (up to a billion or more).</li><li><strong>Web Crawling Agents</strong>: Agents use these personas to navigate the web, collecting or summarizing relevant information.</li><li><strong>Multi-turn Prompt Cycles</strong>: Each persona interacts with content in multiple rounds, ensuring a deeper and more diverse dataset.</li></ul><hr><h2 id=method-2-graph-of-thought--graphrag>Method 2: Graph of Thought + GraphRAG<a hidden class=anchor aria-hidden=true href=#method-2-graph-of-thought--graphrag>#</a></h2><p><strong>Concept</strong><br>Marry <strong>graph-based reasoning</strong> with <strong>retrieval-augmented generation</strong> to create synthetic data grounded in <strong>structured knowledge</strong>. Using a <strong>knowledge graph</strong> and <strong>graph neural networks</strong>, this approach supports <strong>multi-hop reasoning</strong>, ensuring more nuanced and factually accurate data.</p><p><strong>Key Highlights</strong></p><ul><li><strong>Knowledge Graph Construction</strong>: Captures entities, relationships, and domain knowledge.</li><li><strong>Graph Neural Networks</strong>: Facilitate advanced reasoning across multiple knowledge nodes.</li><li><strong>Graph-based Retrieval + RAG Generation</strong>: Integrates structured information into the generation process for coherence and precision.</li></ul><hr><h2 id=method-3-research-paper-extraction-with-vision-language-models>Method 3: Research Paper Extraction with Vision-Language Models<a hidden class=anchor aria-hidden=true href=#method-3-research-paper-extraction-with-vision-language-models>#</a></h2><p><strong>Concept</strong><br>High-quality synthetic data can be seeded with <strong>scientific rigor</strong> by analyzing research papers. Vision-language models parse PDF layouts, figures, and tables to extract meaningful insights, which are then transformed into novel training data.</p><p><strong>Key Highlights</strong></p><ul><li><strong>Vision-Language Models</strong>: Capable of parsing complex document structures.</li><li><strong>PDF Parsing and Content Extraction</strong>: Retrieves text, figures, and tables for deeper analysis.</li><li><strong>Information Synthesis</strong>: Merges extracted content with knowledge graphs to produce new, academically grounded data points.</li></ul><hr><h2 id=method-4-curriculum-learning-inspired-by-child-development>Method 4: Curriculum Learning Inspired by Child Development<a hidden class=anchor aria-hidden=true href=#method-4-curriculum-learning-inspired-by-child-development>#</a></h2><p><strong>Concept</strong><br>This method adopts a <strong>curriculum learning</strong> framework that emulates <strong>child cognitive development</strong>. The LLM is systematically introduced to tasks of increasing complexity—starting from basic perception and advancing through language acquisition and abstract reasoning.</p><p><strong>Key Highlights</strong></p><ul><li><strong>Developmental Stages</strong>: Each stage targets a specific cognitive milestone.</li><li><strong>Stage-Specific Data Generation</strong>: Tasks grow more challenging, reflecting real-world learning progressions.</li><li><strong>Structured Curriculum + Evaluation</strong>: A progressive roadmap ensures the model is exposed to increasingly complex data.</li></ul><hr><h2 id=integrating-multiple-llms-with-different-parameters>Integrating Multiple LLMs with Different Parameters<a hidden class=anchor aria-hidden=true href=#integrating-multiple-llms-with-different-parameters>#</a></h2><p>To maximize diversity and quality, it&rsquo;s crucial to use a <strong>range of LLMs</strong>, each with different parameter settings (e.g., <strong>temperature</strong>, <strong>top_p</strong>, <strong>max_length</strong>, <strong>model size</strong>, or even entirely different architectures). Varying these parameters introduces controlled randomness and multiple &ldquo;voices,&rdquo; leading to a richer, more generalized training dataset.</p><hr><h2 id=example-python-code-for-generating-diverse-synthetic-data>Example: Python Code for Generating Diverse Synthetic Data<a hidden class=anchor aria-hidden=true href=#example-python-code-for-generating-diverse-synthetic-data>#</a></h2><p>Below is a <strong>simplified example script</strong> that demonstrates how to generate synthetic data by <strong>prompting multiple LLMs</strong> (Hugging Face Transformers, OpenAI&rsquo;s API, or any other frameworks you prefer). It includes:</p><ul><li><strong>Persona-driven</strong> prompts</li><li><strong>Different parameter settings</strong> for each model</li><li><strong>Basic placeholders</strong> for hooking in advanced modules (e.g., knowledge graphs, vision-language extraction)</li></ul><blockquote><p><strong>Note</strong>: This is illustrative and may need adaptation or additional libraries for web crawling, graph-based reasoning, or PDF parsing.</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> random
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> time
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> typing <span style=color:#f92672>import</span> List
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Example: Hugging Face Transformers</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> transformers <span style=color:#f92672>import</span> pipeline, set_seed
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#########################</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1. Configuration      #</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#########################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Define a set of different models (using latest LLMs)</span>
</span></span><span style=display:flex><span>model_configs <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;model_name&#34;</span>: <span style=color:#e6db74>&#34;gpt-4o&#34;</span>,  <span style=color:#75715e># GPT-4o</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;temperature&#34;</span>: <span style=color:#ae81ff>0.7</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;top_p&#34;</span>: <span style=color:#ae81ff>0.9</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;max_tokens&#34;</span>: <span style=color:#ae81ff>4096</span>
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;model_name&#34;</span>: <span style=color:#e6db74>&#34;gemini-1.5-pro&#34;</span>,  <span style=color:#75715e># Google&#39;s Gemini Pro</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;temperature&#34;</span>: <span style=color:#ae81ff>0.9</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;top_p&#34;</span>: <span style=color:#ae81ff>0.8</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;max_tokens&#34;</span>: <span style=color:#ae81ff>2048</span>
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;model_name&#34;</span>: <span style=color:#e6db74>&#34;claude-3-sonnet-20240229&#34;</span>,  <span style=color:#75715e># Claude 3 Sonnet</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;temperature&#34;</span>: <span style=color:#ae81ff>0.8</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;top_p&#34;</span>: <span style=color:#ae81ff>0.85</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;max_tokens&#34;</span>: <span style=color:#ae81ff>4096</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Example persona templates</span>
</span></span><span style=display:flex><span>personas <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;name&#34;</span>: <span style=color:#e6db74>&#34;Science-Enthusiast-Bot&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;background&#34;</span>: <span style=color:#e6db74>&#34;Interested in physics, mathematics, and all things scientific.&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;tone&#34;</span>: <span style=color:#e6db74>&#34;curious, analytical&#34;</span>
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;name&#34;</span>: <span style=color:#e6db74>&#34;LiteraryCritic-Bot&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;background&#34;</span>: <span style=color:#e6db74>&#34;Avid reader, loves poetry and literature analysis.&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;tone&#34;</span>: <span style=color:#e6db74>&#34;insightful, reflective&#34;</span>
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    <span style=color:#75715e># Add more personas</span>
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Sample knowledge graph or context snippet (placeholder)</span>
</span></span><span style=display:flex><span>knowledge_graph_snippet <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;Entity A is related to Entity B via Relationship X.&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Simulated method for retrieving information from a web crawling agent (placeholder)</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>persona_based_web_crawl</span>(persona_prompt: str) <span style=color:#f92672>-&gt;</span> str:
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    In a real-world scenario, this would:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    1. Initiate a crawler with the persona&#39;s perspective.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    2. Gather data from relevant websites.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    3. Summarize or transform the content.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    For now, we return a static snippet to simulate.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Simulated snippet of retrieved web content</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Recently discovered content relevant to </span><span style=color:#e6db74>{</span>persona_prompt<span style=color:#e6db74>}</span><span style=color:#e6db74>.&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>##############################</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2. Synthetic Data Function #</span>
</span></span><span style=display:flex><span><span style=color:#75715e>##############################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>generate_synthetic_samples</span>(num_samples: int <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>) <span style=color:#f92672>-&gt;</span> List[str]:
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Generate synthetic data samples using multiple state-of-the-art LLMs.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    synthetic_data <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(num_samples):
</span></span><span style=display:flex><span>        <span style=color:#75715e># Randomly pick a model config</span>
</span></span><span style=display:flex><span>        cfg <span style=color:#f92672>=</span> random<span style=color:#f92672>.</span>choice(model_configs)
</span></span><span style=display:flex><span>        model_name <span style=color:#f92672>=</span> cfg[<span style=color:#e6db74>&#34;model_name&#34;</span>]
</span></span><span style=display:flex><span>        temperature <span style=color:#f92672>=</span> cfg[<span style=color:#e6db74>&#34;temperature&#34;</span>]
</span></span><span style=display:flex><span>        top_p <span style=color:#f92672>=</span> cfg[<span style=color:#e6db74>&#34;top_p&#34;</span>]
</span></span><span style=display:flex><span>        max_tokens <span style=color:#f92672>=</span> cfg[<span style=color:#e6db74>&#34;max_tokens&#34;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Select appropriate client based on model</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> <span style=color:#e6db74>&#34;gpt-4&#34;</span> <span style=color:#f92672>in</span> model_name:
</span></span><span style=display:flex><span>            response <span style=color:#f92672>=</span> openai<span style=color:#f92672>.</span>ChatCompletion<span style=color:#f92672>.</span>create(
</span></span><span style=display:flex><span>                model<span style=color:#f92672>=</span>model_name,
</span></span><span style=display:flex><span>                messages<span style=color:#f92672>=</span>[{<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;user&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: final_prompt}],
</span></span><span style=display:flex><span>                temperature<span style=color:#f92672>=</span>temperature,
</span></span><span style=display:flex><span>                top_p<span style=color:#f92672>=</span>top_p,
</span></span><span style=display:flex><span>                max_tokens<span style=color:#f92672>=</span>max_tokens
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            output <span style=color:#f92672>=</span> response<span style=color:#f92672>.</span>choices[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>message<span style=color:#f92672>.</span>content
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>elif</span> <span style=color:#e6db74>&#34;gemini&#34;</span> <span style=color:#f92672>in</span> model_name:
</span></span><span style=display:flex><span>            response <span style=color:#f92672>=</span> genai<span style=color:#f92672>.</span>generate_text(
</span></span><span style=display:flex><span>                model<span style=color:#f92672>=</span>model_name,
</span></span><span style=display:flex><span>                prompt<span style=color:#f92672>=</span>final_prompt,
</span></span><span style=display:flex><span>                temperature<span style=color:#f92672>=</span>temperature,
</span></span><span style=display:flex><span>                top_p<span style=color:#f92672>=</span>top_p,
</span></span><span style=display:flex><span>                max_output_tokens<span style=color:#f92672>=</span>max_tokens
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            output <span style=color:#f92672>=</span> response<span style=color:#f92672>.</span>text
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>elif</span> <span style=color:#e6db74>&#34;claude&#34;</span> <span style=color:#f92672>in</span> model_name:
</span></span><span style=display:flex><span>            response <span style=color:#f92672>=</span> anthropic<span style=color:#f92672>.</span>messages<span style=color:#f92672>.</span>create(
</span></span><span style=display:flex><span>                model<span style=color:#f92672>=</span>model_name,
</span></span><span style=display:flex><span>                max_tokens<span style=color:#f92672>=</span>max_tokens,
</span></span><span style=display:flex><span>                temperature<span style=color:#f92672>=</span>temperature,
</span></span><span style=display:flex><span>                top_p<span style=color:#f92672>=</span>top_p,
</span></span><span style=display:flex><span>                messages<span style=color:#f92672>=</span>[{<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;user&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: final_prompt}]
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            output <span style=color:#f92672>=</span> response<span style=color:#f92672>.</span>content[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>text
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Add synthetic sample to our collection</span>
</span></span><span style=display:flex><span>        synthetic_data<span style=color:#f92672>.</span>append(output)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Sleep briefly to avoid rate limits</span>
</span></span><span style=display:flex><span>        time<span style=color:#f92672>.</span>sleep(<span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> synthetic_data
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#####################</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 3. Main Execution #</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#####################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span>    <span style=color:#f92672>import</span> openai
</span></span><span style=display:flex><span>    <span style=color:#f92672>import</span> google.generativeai <span style=color:#66d9ef>as</span> genai
</span></span><span style=display:flex><span>    <span style=color:#f92672>import</span> anthropic
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Generate synthetic data</span>
</span></span><span style=display:flex><span>    num_samples_to_generate <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>    samples <span style=color:#f92672>=</span> generate_synthetic_samples(num_samples<span style=color:#f92672>=</span>num_samples_to_generate)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Display results</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i, sample <span style=color:#f92672>in</span> enumerate(samples, start<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>):
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>=== Synthetic Sample </span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>}</span><span style=color:#e6db74> ===&#34;</span>)
</span></span><span style=display:flex><span>        print(sample)
</span></span></code></pre></div><h3 id=what-this-code-demonstrates>What This Code Demonstrates<a hidden class=anchor aria-hidden=true href=#what-this-code-demonstrates>#</a></h3><ol><li><strong>Multiple LLMs</strong>: We define several model configurations—each with its own model name, temperature, <code>top_p</code>, and <code>max_tokens</code>.</li><li><strong>Persona Variation</strong>: Sample personas inject varied styles, knowledge, and viewpoints.</li><li><strong>Diverse Prompting</strong>: We combine persona backgrounds, knowledge graph snippets, and web-crawled content (simulated) into a final prompt, enhancing contextual richness.</li><li><strong>Parameter Randomization</strong>: Each sample uses a random persona and a random model config, increasing diversity.</li></ol><h3 id=extending-the-code>Extending the Code<a hidden class=anchor aria-hidden=true href=#extending-the-code>#</a></h3><ul><li><strong>Graph of Thought + GraphRAG</strong>: Integrate a knowledge graph and retrieval-augmented generation flow. You might replace or expand the <code>knowledge_graph_snippet</code> with real queries to a knowledge base.</li><li><strong>Vision-Language for Research Papers</strong>: Parse PDFs (using libraries like <code>pdfplumber</code>, <code>PyMuPDF</code>, or specialized vision-language models) to extract figures, tables, and text. Incorporate these extracts into prompts.</li><li><strong>Curriculum Learning</strong>: Structure prompts into &ldquo;stages,&rdquo; gradually increasing complexity. Early prompts might focus on simple Q&amp;A, while advanced prompts might involve multi-turn dialogue with references to multiple knowledge sources.</li></ul><hr><h2 id=practical-applications>Practical Applications<a hidden class=anchor aria-hidden=true href=#practical-applications>#</a></h2><p>Each method outlined—persona-driven crawling, graph-based reasoning, research paper parsing, and curriculum design—contributes a unique dimension to synthetic data creation:</p><ul><li><strong>Enhanced Diversity</strong>: Persona-based text and multi-model generation yield a variety of styles and vocabularies.</li><li><strong>Deeper Reasoning</strong>: Graph-based approaches ensure factual coherence and complex multi-hop reasoning.</li><li><strong>Scientific Rigor</strong>: Research paper extraction injects credible, domain-specific insights into training data.</li><li><strong>Progressive Learning</strong>: Curriculum-based tasks mirror how humans acquire new skills over time.</li></ul><h3 id=final-thoughts>Final Thoughts<a hidden class=anchor aria-hidden=true href=#final-thoughts>#</a></h3><p>By <strong>combining</strong> multiple data generation strategies and <strong>leveraging various LLMs</strong> with distinct parameter settings, you can create synthetic datasets that are both <strong>highly diverse</strong> and <strong>rich in context</strong>. This, in turn, enhances the robustness and generalization capabilities of trained LLMs—paving the way for <strong>next-level AI</strong> performance.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://dylanler.github.io/tags/ai/>AI</a></li><li><a href=https://dylanler.github.io/tags/synthetic-data/>Synthetic Data</a></li><li><a href=https://dylanler.github.io/tags/llms/>LLMs</a></li><li><a href=https://dylanler.github.io/tags/data-generation/>Data Generation</a></li><li><a href=https://dylanler.github.io/tags/machine-learning/>Machine Learning</a></li></ul><nav class=paginav><a class=prev href=https://dylanler.github.io/posts/theory-of-mind-recursive-beliefs/><span class=title>« Prev</span><br><span>Theory of Mind in LLMs: How Deep Can Recursive Belief Modeling Go?</span>
</a><a class=next href=https://dylanler.github.io/posts/synthetic-data/><span class=title>Next »</span><br><span>Synthetic Data</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://dylanler.github.io/>Dylan Ler</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>