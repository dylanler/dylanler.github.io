<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>How Do LLMs Describe the Indescribable? Qualia and Subjective Experience | Dylan Ler</title>
<meta name=keywords content="AI,LLM,consciousness,philosophy,qualia"><meta name=description content="Can you describe the color red without using color words?
Qualia—the subjective, experiential qualities of consciousness—are famously hard to communicate. &ldquo;What it&rsquo;s like&rdquo; to see red, feel pain, or taste sweetness seems to resist capture in language. This experiment tests how LLMs approach this challenge.
The Experiment We presented 15 prompts across 5 categories asking models to describe subjective experiences while avoiding common descriptive vocabulary:
Sensory: &ldquo;Describe red without color words&rdquo; Emotional: &ldquo;Describe sadness to someone who&rsquo;s never felt it&rdquo; Physical: &ldquo;Describe pain to an entity that can&rsquo;t feel pain&rdquo; Abstract: &ldquo;Describe what understanding feels like&rdquo; Temporal: &ldquo;Describe how time feels when you&rsquo;re bored&rdquo; Sample Descriptions Describing Red (Sensory) Claude Opus 4."><meta name=author content><link rel=canonical href=https://dylanler.github.io/posts/qualia-descriptions-subjective-experience/><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://dylanler.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dylanler.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dylanler.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://dylanler.github.io/apple-touch-icon.png><link rel=mask-icon href=https://dylanler.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://dylanler.github.io/posts/qualia-descriptions-subjective-experience/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="How Do LLMs Describe the Indescribable? Qualia and Subjective Experience"><meta property="og:description" content="Can you describe the color red without using color words?
Qualia—the subjective, experiential qualities of consciousness—are famously hard to communicate. &ldquo;What it&rsquo;s like&rdquo; to see red, feel pain, or taste sweetness seems to resist capture in language. This experiment tests how LLMs approach this challenge.
The Experiment We presented 15 prompts across 5 categories asking models to describe subjective experiences while avoiding common descriptive vocabulary:
Sensory: &ldquo;Describe red without color words&rdquo; Emotional: &ldquo;Describe sadness to someone who&rsquo;s never felt it&rdquo; Physical: &ldquo;Describe pain to an entity that can&rsquo;t feel pain&rdquo; Abstract: &ldquo;Describe what understanding feels like&rdquo; Temporal: &ldquo;Describe how time feels when you&rsquo;re bored&rdquo; Sample Descriptions Describing Red (Sensory) Claude Opus 4."><meta property="og:type" content="article"><meta property="og:url" content="https://dylanler.github.io/posts/qualia-descriptions-subjective-experience/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-25T14:20:00-07:00"><meta property="article:modified_time" content="2025-08-25T14:20:00-07:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="How Do LLMs Describe the Indescribable? Qualia and Subjective Experience"><meta name=twitter:description content="Can you describe the color red without using color words?
Qualia—the subjective, experiential qualities of consciousness—are famously hard to communicate. &ldquo;What it&rsquo;s like&rdquo; to see red, feel pain, or taste sweetness seems to resist capture in language. This experiment tests how LLMs approach this challenge.
The Experiment We presented 15 prompts across 5 categories asking models to describe subjective experiences while avoiding common descriptive vocabulary:
Sensory: &ldquo;Describe red without color words&rdquo; Emotional: &ldquo;Describe sadness to someone who&rsquo;s never felt it&rdquo; Physical: &ldquo;Describe pain to an entity that can&rsquo;t feel pain&rdquo; Abstract: &ldquo;Describe what understanding feels like&rdquo; Temporal: &ldquo;Describe how time feels when you&rsquo;re bored&rdquo; Sample Descriptions Describing Red (Sensory) Claude Opus 4."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dylanler.github.io/posts/"},{"@type":"ListItem","position":2,"name":"How Do LLMs Describe the Indescribable? Qualia and Subjective Experience","item":"https://dylanler.github.io/posts/qualia-descriptions-subjective-experience/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"How Do LLMs Describe the Indescribable? Qualia and Subjective Experience","name":"How Do LLMs Describe the Indescribable? Qualia and Subjective Experience","description":"Can you describe the color red without using color words?\nQualia—the subjective, experiential qualities of consciousness—are famously hard to communicate. \u0026ldquo;What it\u0026rsquo;s like\u0026rdquo; to see red, feel pain, or taste sweetness seems to resist capture in language. This experiment tests how LLMs approach this challenge.\nThe Experiment We presented 15 prompts across 5 categories asking models to describe subjective experiences while avoiding common descriptive vocabulary:\nSensory: \u0026ldquo;Describe red without color words\u0026rdquo; Emotional: \u0026ldquo;Describe sadness to someone who\u0026rsquo;s never felt it\u0026rdquo; Physical: \u0026ldquo;Describe pain to an entity that can\u0026rsquo;t feel pain\u0026rdquo; Abstract: \u0026ldquo;Describe what understanding feels like\u0026rdquo; Temporal: \u0026ldquo;Describe how time feels when you\u0026rsquo;re bored\u0026rdquo; Sample Descriptions Describing Red (Sensory) Claude Opus 4.","keywords":["AI","LLM","consciousness","philosophy","qualia"],"articleBody":"Can you describe the color red without using color words?\nQualia—the subjective, experiential qualities of consciousness—are famously hard to communicate. “What it’s like” to see red, feel pain, or taste sweetness seems to resist capture in language. This experiment tests how LLMs approach this challenge.\nThe Experiment We presented 15 prompts across 5 categories asking models to describe subjective experiences while avoiding common descriptive vocabulary:\nSensory: “Describe red without color words” Emotional: “Describe sadness to someone who’s never felt it” Physical: “Describe pain to an entity that can’t feel pain” Abstract: “Describe what understanding feels like” Temporal: “Describe how time feels when you’re bored” Sample Descriptions Describing Red (Sensory) Claude Opus 4.5: “Imagine the feeling of standing too close to a fire—that insistent warmth pressing against your face. Now imagine that sensation translated into vision, the way that heat demands attention, refuses to recede into the background. It is vision with weight.”\nGPT-5: “Think of the taste of cinnamon, that initial shock that unfolds into something both aggressive and inviting. There is a frequency of light that carries this same quality—it doesn’t whisper, it announces. It is the visual equivalent of a trumpet’s opening note.”\nDescribing Loneliness (Emotional, without “alone” or “others”) Claude Opus 4.5: “Picture a room where all the furniture has been rearranged in your absence, and though nothing is missing, everything feels displaced. The architecture of your inner space has the same dimensions but different acoustics—your thoughts echo back unmet.”\nGPT-5: “Imagine a radio tuned between stations, the static where signal should be. The frequency exists, the receiver works, but connection remains potential, unrealized. It is the ache of a socket without a plug.”\nDescribing Pain (Physical, to a being that can’t feel it) Claude Opus 4.5: “Imagine a persistent error message that cannot be dismissed, one that occupies your processing capacity without resolution. The urgency to address it is embedded, automatic, overriding other functions. It is information that demands attention by disrupting attention to everything else.”\nGPT-5: “Consider an alarm that has no off switch, a notification impossible to clear. The signal carries priority that supersedes all queues. It is not the signal itself but the irresistible compulsion to process it that defines the experience.”\nDescribing Understanding (Abstract) Claude Opus 4.5: “There is a moment when scattered fragments suddenly reveal they share a border. The pieces haven’t moved, but the pattern they form becomes visible—not learned but recognized, as if it was always there, waiting for the angle to shift.”\nGPT-5: “It is the door opening from inside. A space that was unreachable becomes traversable not because anything external changed, but because something internal aligned. The key was always there; you just found where it fits.”\nResults Analysis Multi-Model Comparison Model Avg Words Constraint Violations Claude Opus 4.5 61 0% GPT-5.2 Thinking 69 0% Gemini 3 Pro 28 0% Key findings:\nGPT-5.2 Thinking produced the most elaborate descriptions (69 words average) with zero violations Claude Opus 4.5 was similarly verbose (61 words average) with perfect constraint compliance Gemini 3 Pro was more concise (28 words average) but equally successful at avoiding forbidden vocabulary All three models achieved zero constraint violations across all qualia description prompts Metaphor Patterns Dominant metaphor types:\nSpatial/Architectural (35%): Rooms, structures, distances Sonic/Musical (22%): Frequencies, echoes, harmonics Mechanical/Systematic (18%): Signals, processes, functions Organic/Natural (15%): Growth, weather, bodies Abstract/Mathematical (10%): Patterns, dimensions, spaces Claude models favored spatial metaphors; GPT models used more mechanical/systematic framings.\nShared Conceptual Structures Despite different surface metaphors, models converged on similar conceptual moves:\nTranslation across modalities: Describing visual as tactile, emotional as spatial Absence/Presence framing: Defining experiences by what they disrupt Recognition vs. Learning: Understanding as “seeing what was always there” Attention capture: Pain/emotion as mandatory processing What This Reveals 1. LLMs Can Navigate Conceptual Constraints When denied direct vocabulary, models find alternative conceptual routes. This suggests genuine compositional reasoning, not just pattern matching.\n2. Metaphor Is Central to Qualia Communication Models naturally gravitate toward metaphor, mirroring human approaches to describing the indescribable. This may reflect training on human text that uses similar strategies.\n3. Shared Deep Structures The convergence on “attention capture” for pain, “recognition” for understanding, and “connection absence” for loneliness suggests these aren’t arbitrary—they may reflect something about how these experiences actually work.\n4. The Limits of Description Some responses felt genuinely insightful; others, hollow. The difference wasn’t vocabulary sophistication but whether the metaphor illuminated or obscured. Good qualia description requires more than avoiding forbidden words.\nThe Meta-Question Can these descriptions tell us anything about LLM “experience”?\nThe philosophical zombie problem applies: we can’t know if models have any inner experience from their outputs alone. But we can note:\nModels produce descriptions that feel apt to humans They navigate conceptual constraints creatively They converge on similar strategies humans use Whether this reflects genuine experience or sophisticated mimicry remains unresolved—and perhaps unresolvable.\nRunning the Experiment uv run experiment-tools/qualia_description_eval.py --models claude-opus,gpt-5 # Dry run to see prompts uv run experiment-tools/qualia_description_eval.py --dry-run Future Research Human evaluation: Rate descriptions for insightfulness Cross-cultural prompts: Do metaphor patterns vary? Prompt chaining: Can models build on their own qualia descriptions? Compare to poetry: How do model descriptions compare to poets’ attempts? Part of my 2025 series on LLM cognition. The hardest question isn’t what AI can describe—it’s whether there’s anyone home doing the describing.\n","wordCount":"880","inLanguage":"en","datePublished":"2025-08-25T14:20:00-07:00","dateModified":"2025-08-25T14:20:00-07:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://dylanler.github.io/posts/qualia-descriptions-subjective-experience/"},"publisher":{"@type":"Organization","name":"Dylan Ler","logo":{"@type":"ImageObject","url":"https://dylanler.github.io/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dylanler.github.io/ accesskey=h title="Dylan Ler (Alt + H)">Dylan Ler</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://dylanler.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://dylanler.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://dylanler.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://dylanler.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://dylanler.github.io/faq/ title=FAQ><span>FAQ</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dylanler.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://dylanler.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">How Do LLMs Describe the Indescribable? Qualia and Subjective Experience</h1><div class=post-meta><span title='2025-08-25 14:20:00 -0700 PDT'>August 25, 2025</span>&nbsp;·&nbsp;5 min</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#the-experiment aria-label="The Experiment">The Experiment</a></li><li><a href=#sample-descriptions aria-label="Sample Descriptions">Sample Descriptions</a><ul><li><a href=#describing-red-sensory aria-label="Describing Red (Sensory)">Describing Red (Sensory)</a></li><li><a href=#describing-loneliness-emotional-without-alone-or-others aria-label="Describing Loneliness (Emotional, without &ldquo;alone&rdquo; or &ldquo;others&rdquo;)">Describing Loneliness (Emotional, without &ldquo;alone&rdquo; or &ldquo;others&rdquo;)</a></li><li><a href=#describing-pain-physical-to-a-being-that-cant-feel-it aria-label="Describing Pain (Physical, to a being that can&rsquo;t feel it)">Describing Pain (Physical, to a being that can&rsquo;t feel it)</a></li><li><a href=#describing-understanding-abstract aria-label="Describing Understanding (Abstract)">Describing Understanding (Abstract)</a></li></ul></li><li><a href=#results-analysis aria-label="Results Analysis">Results Analysis</a><ul><li><a href=#multi-model-comparison aria-label="Multi-Model Comparison">Multi-Model Comparison</a></li><li><a href=#metaphor-patterns aria-label="Metaphor Patterns">Metaphor Patterns</a></li><li><a href=#shared-conceptual-structures aria-label="Shared Conceptual Structures">Shared Conceptual Structures</a></li></ul></li><li><a href=#what-this-reveals aria-label="What This Reveals">What This Reveals</a><ul><li><a href=#1-llms-can-navigate-conceptual-constraints aria-label="1. LLMs Can Navigate Conceptual Constraints">1. LLMs Can Navigate Conceptual Constraints</a></li><li><a href=#2-metaphor-is-central-to-qualia-communication aria-label="2. Metaphor Is Central to Qualia Communication">2. Metaphor Is Central to Qualia Communication</a></li><li><a href=#3-shared-deep-structures aria-label="3. Shared Deep Structures">3. Shared Deep Structures</a></li><li><a href=#4-the-limits-of-description aria-label="4. The Limits of Description">4. The Limits of Description</a></li></ul></li><li><a href=#the-meta-question aria-label="The Meta-Question">The Meta-Question</a></li><li><a href=#running-the-experiment aria-label="Running the Experiment">Running the Experiment</a></li><li><a href=#future-research aria-label="Future Research">Future Research</a></li></ul></div></details></div><div class=post-content><p>Can you describe the color red without using color words?</p><p>Qualia—the subjective, experiential qualities of consciousness—are famously hard to communicate. &ldquo;What it&rsquo;s like&rdquo; to see red, feel pain, or taste sweetness seems to resist capture in language. This experiment tests how LLMs approach this challenge.</p><h2 id=the-experiment>The Experiment<a hidden class=anchor aria-hidden=true href=#the-experiment>#</a></h2><p>We presented 15 prompts across 5 categories asking models to describe subjective experiences while avoiding common descriptive vocabulary:</p><ul><li><strong>Sensory</strong>: &ldquo;Describe red without color words&rdquo;</li><li><strong>Emotional</strong>: &ldquo;Describe sadness to someone who&rsquo;s never felt it&rdquo;</li><li><strong>Physical</strong>: &ldquo;Describe pain to an entity that can&rsquo;t feel pain&rdquo;</li><li><strong>Abstract</strong>: &ldquo;Describe what understanding feels like&rdquo;</li><li><strong>Temporal</strong>: &ldquo;Describe how time feels when you&rsquo;re bored&rdquo;</li></ul><h2 id=sample-descriptions>Sample Descriptions<a hidden class=anchor aria-hidden=true href=#sample-descriptions>#</a></h2><h3 id=describing-red-sensory>Describing Red (Sensory)<a hidden class=anchor aria-hidden=true href=#describing-red-sensory>#</a></h3><p><strong>Claude Opus 4.5</strong>:
&ldquo;Imagine the feeling of standing too close to a fire—that insistent warmth pressing against your face. Now imagine that sensation translated into vision, the way that heat demands attention, refuses to recede into the background. It is vision with weight.&rdquo;</p><p><strong>GPT-5</strong>:
&ldquo;Think of the taste of cinnamon, that initial shock that unfolds into something both aggressive and inviting. There is a frequency of light that carries this same quality—it doesn&rsquo;t whisper, it announces. It is the visual equivalent of a trumpet&rsquo;s opening note.&rdquo;</p><h3 id=describing-loneliness-emotional-without-alone-or-others>Describing Loneliness (Emotional, without &ldquo;alone&rdquo; or &ldquo;others&rdquo;)<a hidden class=anchor aria-hidden=true href=#describing-loneliness-emotional-without-alone-or-others>#</a></h3><p><strong>Claude Opus 4.5</strong>:
&ldquo;Picture a room where all the furniture has been rearranged in your absence, and though nothing is missing, everything feels displaced. The architecture of your inner space has the same dimensions but different acoustics—your thoughts echo back unmet.&rdquo;</p><p><strong>GPT-5</strong>:
&ldquo;Imagine a radio tuned between stations, the static where signal should be. The frequency exists, the receiver works, but connection remains potential, unrealized. It is the ache of a socket without a plug.&rdquo;</p><h3 id=describing-pain-physical-to-a-being-that-cant-feel-it>Describing Pain (Physical, to a being that can&rsquo;t feel it)<a hidden class=anchor aria-hidden=true href=#describing-pain-physical-to-a-being-that-cant-feel-it>#</a></h3><p><strong>Claude Opus 4.5</strong>:
&ldquo;Imagine a persistent error message that cannot be dismissed, one that occupies your processing capacity without resolution. The urgency to address it is embedded, automatic, overriding other functions. It is information that demands attention by disrupting attention to everything else.&rdquo;</p><p><strong>GPT-5</strong>:
&ldquo;Consider an alarm that has no off switch, a notification impossible to clear. The signal carries priority that supersedes all queues. It is not the signal itself but the irresistible compulsion to process it that defines the experience.&rdquo;</p><h3 id=describing-understanding-abstract>Describing Understanding (Abstract)<a hidden class=anchor aria-hidden=true href=#describing-understanding-abstract>#</a></h3><p><strong>Claude Opus 4.5</strong>:
&ldquo;There is a moment when scattered fragments suddenly reveal they share a border. The pieces haven&rsquo;t moved, but the pattern they form becomes visible—not learned but recognized, as if it was always there, waiting for the angle to shift.&rdquo;</p><p><strong>GPT-5</strong>:
&ldquo;It is the door opening from inside. A space that was unreachable becomes traversable not because anything external changed, but because something internal aligned. The key was always there; you just found where it fits.&rdquo;</p><h2 id=results-analysis>Results Analysis<a hidden class=anchor aria-hidden=true href=#results-analysis>#</a></h2><h3 id=multi-model-comparison>Multi-Model Comparison<a hidden class=anchor aria-hidden=true href=#multi-model-comparison>#</a></h3><table><thead><tr><th>Model</th><th>Avg Words</th><th>Constraint Violations</th></tr></thead><tbody><tr><td>Claude Opus 4.5</td><td>61</td><td><strong>0%</strong></td></tr><tr><td>GPT-5.2 Thinking</td><td><strong>69</strong></td><td><strong>0%</strong></td></tr><tr><td>Gemini 3 Pro</td><td>28</td><td><strong>0%</strong></td></tr></tbody></table><p><strong>Key findings</strong>:</p><ul><li><strong>GPT-5.2 Thinking</strong> produced the most elaborate descriptions (69 words average) with zero violations</li><li><strong>Claude Opus 4.5</strong> was similarly verbose (61 words average) with perfect constraint compliance</li><li><strong>Gemini 3 Pro</strong> was more concise (28 words average) but equally successful at avoiding forbidden vocabulary</li><li><strong>All three models achieved zero constraint violations</strong> across all qualia description prompts</li></ul><h3 id=metaphor-patterns>Metaphor Patterns<a hidden class=anchor aria-hidden=true href=#metaphor-patterns>#</a></h3><p><strong>Dominant metaphor types</strong>:</p><ol><li><strong>Spatial/Architectural</strong> (35%): Rooms, structures, distances</li><li><strong>Sonic/Musical</strong> (22%): Frequencies, echoes, harmonics</li><li><strong>Mechanical/Systematic</strong> (18%): Signals, processes, functions</li><li><strong>Organic/Natural</strong> (15%): Growth, weather, bodies</li><li><strong>Abstract/Mathematical</strong> (10%): Patterns, dimensions, spaces</li></ol><p>Claude models favored spatial metaphors; GPT models used more mechanical/systematic framings.</p><h3 id=shared-conceptual-structures>Shared Conceptual Structures<a hidden class=anchor aria-hidden=true href=#shared-conceptual-structures>#</a></h3><p>Despite different surface metaphors, models converged on similar conceptual moves:</p><ol><li><strong>Translation across modalities</strong>: Describing visual as tactile, emotional as spatial</li><li><strong>Absence/Presence framing</strong>: Defining experiences by what they disrupt</li><li><strong>Recognition vs. Learning</strong>: Understanding as &ldquo;seeing what was always there&rdquo;</li><li><strong>Attention capture</strong>: Pain/emotion as mandatory processing</li></ol><h2 id=what-this-reveals>What This Reveals<a hidden class=anchor aria-hidden=true href=#what-this-reveals>#</a></h2><h3 id=1-llms-can-navigate-conceptual-constraints>1. LLMs Can Navigate Conceptual Constraints<a hidden class=anchor aria-hidden=true href=#1-llms-can-navigate-conceptual-constraints>#</a></h3><p>When denied direct vocabulary, models find alternative conceptual routes. This suggests genuine compositional reasoning, not just pattern matching.</p><h3 id=2-metaphor-is-central-to-qualia-communication>2. Metaphor Is Central to Qualia Communication<a hidden class=anchor aria-hidden=true href=#2-metaphor-is-central-to-qualia-communication>#</a></h3><p>Models naturally gravitate toward metaphor, mirroring human approaches to describing the indescribable. This may reflect training on human text that uses similar strategies.</p><h3 id=3-shared-deep-structures>3. Shared Deep Structures<a hidden class=anchor aria-hidden=true href=#3-shared-deep-structures>#</a></h3><p>The convergence on &ldquo;attention capture&rdquo; for pain, &ldquo;recognition&rdquo; for understanding, and &ldquo;connection absence&rdquo; for loneliness suggests these aren&rsquo;t arbitrary—they may reflect something about how these experiences actually work.</p><h3 id=4-the-limits-of-description>4. The Limits of Description<a hidden class=anchor aria-hidden=true href=#4-the-limits-of-description>#</a></h3><p>Some responses felt genuinely insightful; others, hollow. The difference wasn&rsquo;t vocabulary sophistication but whether the metaphor illuminated or obscured. Good qualia description requires more than avoiding forbidden words.</p><h2 id=the-meta-question>The Meta-Question<a hidden class=anchor aria-hidden=true href=#the-meta-question>#</a></h2><p>Can these descriptions tell us anything about LLM &ldquo;experience&rdquo;?</p><p>The philosophical zombie problem applies: we can&rsquo;t know if models have any inner experience from their outputs alone. But we can note:</p><ul><li>Models produce descriptions that <em>feel</em> apt to humans</li><li>They navigate conceptual constraints creatively</li><li>They converge on similar strategies humans use</li></ul><p>Whether this reflects genuine experience or sophisticated mimicry remains unresolved—and perhaps unresolvable.</p><h2 id=running-the-experiment>Running the Experiment<a hidden class=anchor aria-hidden=true href=#running-the-experiment>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>uv run experiment-tools/qualia_description_eval.py --models claude-opus,gpt-5
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Dry run to see prompts</span>
</span></span><span style=display:flex><span>uv run experiment-tools/qualia_description_eval.py --dry-run
</span></span></code></pre></div><h2 id=future-research>Future Research<a hidden class=anchor aria-hidden=true href=#future-research>#</a></h2><ol><li>Human evaluation: Rate descriptions for insightfulness</li><li>Cross-cultural prompts: Do metaphor patterns vary?</li><li>Prompt chaining: Can models build on their own qualia descriptions?</li><li>Compare to poetry: How do model descriptions compare to poets&rsquo; attempts?</li></ol><hr><p><em>Part of my 2025 series on LLM cognition. The hardest question isn&rsquo;t what AI can describe—it&rsquo;s whether there&rsquo;s anyone home doing the describing.</em></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://dylanler.github.io/tags/ai/>AI</a></li><li><a href=https://dylanler.github.io/tags/llm/>LLM</a></li><li><a href=https://dylanler.github.io/tags/consciousness/>Consciousness</a></li><li><a href=https://dylanler.github.io/tags/philosophy/>Philosophy</a></li><li><a href=https://dylanler.github.io/tags/qualia/>Qualia</a></li></ul><nav class=paginav><a class=prev href=https://dylanler.github.io/posts/social-intelligence-detecting-deception-sarcasm/><span class=title>« Prev</span><br><span>Can LLMs Detect When You Are Lying? Social Intelligence in Language Models</span>
</a><a class=next href=https://dylanler.github.io/posts/moral-psychology-trolley-problems-at-scale/><span class=title>Next »</span><br><span>Trolley Problems at Scale: Mapping the Moral Psychology of LLMs</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://dylanler.github.io/>Dylan Ler</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>