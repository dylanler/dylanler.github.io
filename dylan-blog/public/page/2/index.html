<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.133.0"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Dylan Ler</title>
<meta name=description content><meta name=author content><link rel=canonical href=https://dylanler.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://dylanler.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dylanler.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dylanler.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://dylanler.github.io/apple-touch-icon.png><link rel=mask-icon href=https://dylanler.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://dylanler.github.io/index.xml><link rel=alternate type=application/json href=https://dylanler.github.io/index.json><link rel=alternate hreflang=en href=https://dylanler.github.io/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="Dylan Ler"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://dylanler.github.io/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Dylan Ler"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Dylan Ler","url":"https://dylanler.github.io/","description":"","thumbnailUrl":"https://dylanler.github.io/favicon.ico","sameAs":["/index.xml","https://github.com/dylanler","https://github.com/dylanler","https://twitter.com/sog_on_bird_app"]}</script></head><body class="list dark" id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dylanler.github.io/ accesskey=h title="Dylan Ler (Alt + H)">Dylan Ler</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://dylanler.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://dylanler.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://dylanler.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://dylanler.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://dylanler.github.io/faq/ title=FAQ><span>FAQ</span></a></li></ul></nav></header><main class=main><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Can LLMs Have Taste? Mapping Aesthetic Preferences Across AI Models</h2></header><div class=entry-content><p>Do AI systems have genuine aesthetic preferences, or are they just pattern-matching to training data?
This experiment probes the aesthetic ‚Äútaste‚Äù of different LLMs across art, poetry, music, design, and writing‚Äîtesting whether they exhibit consistent, model-specific preferences.
The Experiment We presented 15 aesthetic comparison pairs across 5 domains:
Visual Art: Abstract vs. representational, minimal vs. complex Poetry: Rhyming vs. free verse, dense vs. sparse Music: Harmonic vs. dissonant, simple vs. complex Design: Ornate vs....</p></div><footer class=entry-footer><span title='2025-05-08 16:42:00 -0700 PDT'>May 8, 2025</span>&nbsp;¬∑&nbsp;4 min</footer><a class=entry-link aria-label="post link to Can LLMs Have Taste? Mapping Aesthetic Preferences Across AI Models" href=https://dylanler.github.io/posts/aesthetic-judgment-can-llms-have-taste/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Wisdom of Crowds: What LLM Disagreement Reveals About AI Uncertainty</h2></header><div class=entry-content><p>When multiple AI models disagree, what does that tell us?
The ‚Äúwisdom of crowds‚Äù phenomenon shows that aggregating independent judgments often outperforms individual experts. But for AI systems, ensemble disagreement might reveal something deeper: the structure of uncertainty itself.
The Hypothesis When multiple LLMs disagree on a question, the pattern of disagreement reveals the epistemological nature of the problem:
High agreement ‚Üí Robust, well-established knowledge Systematic disagreement ‚Üí Genuine ambiguity or value-laden territory Random disagreement ‚Üí Knowledge gaps or reasoning failures Experiment Design We queried 4 models (Claude Opus 4....</p></div><footer class=entry-footer><span title='2025-04-22 10:15:00 -0700 PDT'>April 22, 2025</span>&nbsp;¬∑&nbsp;3 min</footer><a class=entry-link aria-label="post link to Wisdom of Crowds: What LLM Disagreement Reveals About AI Uncertainty" href=https://dylanler.github.io/posts/wisdom-of-crowds-ensemble-disagreement/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Creating Cross-Pollinated SFT Training Dataset for Novel Knowledge Recombination</h2></header><div class=entry-content><p>In the realm of large language models (LLMs), the quality and diversity of training data significantly impact a model‚Äôs ability to generate creative, insightful responses. While traditional training approaches often treat different knowledge domains as separate silos, there‚Äôs a compelling opportunity to create more versatile models by deliberately cross-pollinating knowledge across domains.
This blog post explores a methodology for creating a specialized Supervised Fine-Tuning (SFT) dataset that deliberately bridges diverse knowledge domains‚Äîspecifically, how to extract, align, and combine content from textbooks of vastly different genres such as mathematics and history....</p></div><footer class=entry-footer><span title='2025-03-13 03:41:39 -0700 PDT'>March 13, 2025</span>&nbsp;¬∑&nbsp;8 min</footer><a class=entry-link aria-label="post link to Creating Cross-Pollinated SFT Training Dataset for Novel Knowledge Recombination" href=https://dylanler.github.io/posts/creating-cross-polinated-sft-training-dataset/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Creating a Video Dataset With Precise Camera Movement Prompts</h2></header><div class=entry-content><p>Creating a Video Dataset with Precise Camera Movement Prompts In the world of AI video generation, one of the most challenging aspects is controlling camera movement. Whether you‚Äôre developing a text-to-video model or researching video understanding, having a dataset with precise camera movement annotations is invaluable. This post outlines a comprehensive approach to creating such a dataset using cutting-edge AI tools and techniques.
Why Create a Camera Movement Dataset? Camera movements like panning, tilting, zooming, and tracking shots are fundamental cinematographic techniques that convey spatial relationships and direct viewer attention....</p></div><footer class=entry-footer><span title='2025-03-11 03:30:25 -0700 PDT'>March 11, 2025</span>&nbsp;¬∑&nbsp;9 min</footer><a class=entry-link aria-label="post link to Creating a Video Dataset With Precise Camera Movement Prompts" href=https://dylanler.github.io/posts/creating-a-video-dataset-with-precise-camera-movement-prompt/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Enhancing LLM Reasoning: Chain of Draft with Semantically Diverse Thinking Tokens Using GRPO</h2></header><div class=entry-content><p>Enhancing LLM Reasoning: Chain of Draft with Semantically Diverse Thinking Tokens Using GRPO The Challenge: Efficient Reasoning in LLMs Large Language Models (LLMs) have become remarkably capable at complex reasoning tasks, but this often comes at a cost: verbose outputs that consume significant computational resources. The Chain of Thought (CoT) prompting technique, while effective for accuracy, generates lengthy reasoning steps that increase token usage and latency.
Enter Chain of Draft (CoD), a promising alternative introduced by Xu et al....</p></div><footer class=entry-footer><span title='2025-03-05 00:00:00 +0000 UTC'>March 5, 2025</span>&nbsp;¬∑&nbsp;19 min</footer><a class=entry-link aria-label="post link to Enhancing LLM Reasoning: Chain of Draft with Semantically Diverse Thinking Tokens Using GRPO" href=https://dylanler.github.io/posts/chain-of-draft-with-semantically-diverse-thinking-tokens/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Theory of Mind in LLMs: How Deep Can Recursive Belief Modeling Go?</h2></header><div class=entry-content><p>Can AI understand what you think I think you think?
Theory of Mind (ToM)‚Äîthe ability to attribute mental states to others‚Äîis considered a hallmark of human social intelligence. We naturally track what others believe, want, and intend. But it gets harder when beliefs nest: understanding what Alice thinks Bob believes about Carol‚Äôs intentions requires recursive modeling that strains even human cognition.
This experiment tests how deep LLMs can go in recursive belief modeling....</p></div><footer class=entry-footer><span title='2025-02-17 14:23:00 -0800 PST'>February 17, 2025</span>&nbsp;¬∑&nbsp;5 min</footer><a class=entry-link aria-label="post link to Theory of Mind in LLMs: How Deep Can Recursive Belief Modeling Go?" href=https://dylanler.github.io/posts/theory-of-mind-recursive-beliefs/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Synthetic Data Experiments with LLMs</h2></header><div class=entry-content><p>Generating High-Quality Synthetic Data for Large Language Models Introduction In the dynamic landscape of artificial intelligence (AI), Large Language Models (LLMs) stand out for their remarkable ability to understand and generate human-like text. Their performance, however, is largely influenced by the quality and diversity of their training data. This guide explores four innovative methods for generating high-quality synthetic data‚Äîeach designed to broaden LLMs‚Äô capabilities and help them excel across a wide range of tasks....</p></div><footer class=entry-footer><span title='2025-01-19 20:45:48 -0800 PST'>January 19, 2025</span>&nbsp;¬∑&nbsp;7 min</footer><a class=entry-link aria-label="post link to Synthetic Data Experiments with LLMs" href=https://dylanler.github.io/posts/synthetic-data-experiments/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Synthetic Data</h2></header><div class=entry-content><p>Generating Synthetic Data for Large Language Models: A Comprehensive Guide In the rapidly evolving field of artificial intelligence, the quality and diversity of training data play a pivotal role in the capabilities of Large Language Models (LLMs). This guide delves into four innovative methods designed to generate high-quality synthetic data, aiming to significantly enhance LLM performance across a variety of tasks. Whether you‚Äôre a researcher, developer, or AI enthusiast, understanding these methods can provide valuable insights into the future of AI training and development....</p></div><footer class=entry-footer><span title='2024-08-19 02:19:26 -0700 PDT'>August 19, 2024</span>&nbsp;¬∑&nbsp;4 min</footer><a class=entry-link aria-label="post link to Synthetic Data" href=https://dylanler.github.io/posts/synthetic-data/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Self Help Books</h2></header><div class=entry-content><p>Thoughts about self-help books üìö People often ask me to recommend a self-help book that might help them achieve something be it losing weight, investing, building careers and etc.
Till date I always have the same reply, ‚ÄúI don‚Äôt read self-help books‚Äù.
I mean I‚Äôm sure self-help books can be useful if you can apply what the author is asking you to do seamlessly into your life. However I find that to be easier said than done....</p></div><footer class=entry-footer><span title='2018-11-08 22:40:56 -0700 -0700'>November 8, 2018</span>&nbsp;¬∑&nbsp;2 min</footer><a class=entry-link aria-label="post link to Self Help Books" href=https://dylanler.github.io/posts/self-help-books/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>It's Hard to Notice the Little Things</h2></header><div class=entry-content><p>For the past few weeks, I‚Äôve been listening to startup founders about how they scaled their companies while preserving their core values at the same time. As such, I will be summarizing some of the recurring elements that stood out to me.
One thing that really surprised me is that really large companies are not run as efficiently as you think. A lot of times, bureaucracy gets piled up that causes employees to lose the initial spark they had when they joined the company....</p></div><footer class=entry-footer><span title='2015-11-19 00:00:00 -0700 -0700'>November 19, 2015</span>&nbsp;¬∑&nbsp;5 min</footer><a class=entry-link aria-label="post link to It's Hard to Notice the Little Things" href=https://dylanler.github.io/posts/the-little-things/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://dylanler.github.io/>¬´&nbsp;Prev&nbsp;
</a><a class=next href=https://dylanler.github.io/page/3/>Next&nbsp;&nbsp;¬ª</a></nav></footer></main><footer class=footer><span>&copy; 2026 <a href=https://dylanler.github.io/>Dylan Ler</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>